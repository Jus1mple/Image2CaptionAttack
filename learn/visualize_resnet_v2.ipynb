{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tfs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cal_cam(nn.Module):\n",
    "    def __init__(self, feature_layer=\"layer4\"):\n",
    "        super(cal_cam, self).__init__()\n",
    "        # self.model = models.resnet50(pretrained=False)\n",
    "        # path = r\"C:\\Users\\Matt\\.cache\\clip\\RN50.pt\"\n",
    "        # self.model.load_state_dict(torch.load(path))\n",
    "        # 加载ResNet模型\n",
    "        clip_model, _ = clip.load(\"RN50\", device=\"cuda:0\")\n",
    "        clip_model = clip_model.to(torch.float)\n",
    "        self.model = clip_model.visual\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 要求梯度的层\n",
    "        self.feature_layer = feature_layer\n",
    "        # 记录梯度\n",
    "        self.gradient = []\n",
    "        # 记录输出的特征图\n",
    "        self.output = []\n",
    "        self.means = [0.485, 0.456, 0.406]\n",
    "        self.stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "        self.trainsform = tfs.Compose([\n",
    "            tfs.ToTensor(),\n",
    "            tfs.Normalize(self.means, self.stds)\n",
    "        ])\n",
    "\n",
    "    def save_grad(self, grad):\n",
    "        self.gradient.append(grad)\n",
    "\n",
    "    def get_grad(self):\n",
    "        return self.gradient[-1].cpu().data\n",
    "\n",
    "    def get_feature(self):\n",
    "        return self.output[-1][0]\n",
    "\n",
    "    def process_img(self, input):\n",
    "        input = self.trainsform(input)\n",
    "        input = input.unsqueeze(0)\n",
    "        return input\n",
    "\n",
    "    # 计算最后一个卷积层的梯度，输出梯度和最后一个卷积层的特征图\n",
    "    def getGrad(self, input_):\n",
    "        input_ = input_.to(self.device).requires_grad_(True)\n",
    "        num = 1\n",
    "        for name, module in self.model._modules.items():\n",
    "            if (num == 1):\n",
    "                input = module(input_)\n",
    "                num = num + 1\n",
    "                continue\n",
    "            # 是待提取特征图的层\n",
    "            if (name == self.feature_layer):\n",
    "                input = module(input)\n",
    "                input.register_hook(self.save_grad)\n",
    "                self.output.append([input])\n",
    "            # 马上要到全连接层了\n",
    "            elif (name == \"avgpool\"):\n",
    "                input = module(input)\n",
    "                input = input.reshape(input.shape[0], -1)\n",
    "            # 普通的层\n",
    "            else:\n",
    "                input = module(input)\n",
    "\n",
    "        # 到这里input就是最后全连接层的输出了\n",
    "        index = torch.max(input, dim=-1)[1]\n",
    "        one_hot = torch.zeros((1, input.shape[-1]), dtype=torch.float32)\n",
    "        one_hot[0][index] = 1\n",
    "        confidenct = one_hot * input.cpu()\n",
    "        confidenct = torch.sum(confidenct, dim=-1).requires_grad_(True)\n",
    "        # print(confidenct)\n",
    "        self.model.zero_grad()\n",
    "        # 反向传播获取梯度\n",
    "        confidenct.backward(retain_graph=True)\n",
    "        # 获取特征图的梯度\n",
    "        grad_val = self.get_grad()\n",
    "        feature = self.get_feature()\n",
    "        return grad_val, feature, input_.grad\n",
    "\n",
    "    # 计算CAM\n",
    "    def getCam(self, grad_val, feature):\n",
    "        # 对特征图的每个通道进行全局池化\n",
    "        alpha = torch.mean(grad_val, dim=(2, 3)).cpu()\n",
    "        feature = feature.cpu()\n",
    "        # 将池化后的结果和相应通道特征图相乘\n",
    "        cam = torch.zeros((feature.shape[2], feature.shape[3]), dtype=torch.float32)\n",
    "        for idx in range(alpha.shape[1]):\n",
    "            cam = cam + alpha[0][idx] * feature[0][idx]\n",
    "        # 进行ReLU操作\n",
    "        cam = np.maximum(cam.detach().numpy(), 0)\n",
    "\n",
    "        plt.imshow(cam)\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"cam.jpg\")\n",
    "\n",
    "        # 将cam区域放大到输入图片大小\n",
    "        cam_ = cv2.resize(cam, (224, 224))\n",
    "        cam_ = cam_ - np.min(cam_)\n",
    "        cam_ = cam_ / np.max(cam_)\n",
    "        plt.imshow(cam_)\n",
    "        plt.savefig(\"cam_.jpg\")\n",
    "        cam = torch.from_numpy(cam)\n",
    "\n",
    "        return cam, cam_\n",
    "\n",
    "    def show_img(self, cam_, img):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam_), cv2.COLORMAP_JET)\n",
    "        cam_img = 0.3 * heatmap + 0.7 * np.float32(img)\n",
    "        cv2.imwrite(\"img.jpg\", cam_img)\n",
    "\n",
    "    def __call__(self, img_root):\n",
    "        img = Image.open(img_root)\n",
    "        img = img.resize((224, 224))\n",
    "        plt.imshow(img)\n",
    "        plt.savefig(\"airplane.jpg\")\n",
    "        input = self.process_img(img)\n",
    "        grad_val, feature, input_grad = self.getGrad(input)\n",
    "        cam, cam_ = self.getCam(grad_val, feature)\n",
    "        self.show_img(cam_, img)\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\serialization.py:707: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RecursiveScriptModule' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cam \u001b[38;5;241m=\u001b[39m cal_cam()\n\u001b[0;32m      2\u001b[0m img_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAutoDL_backup\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimage_caption_generation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCOCO2017\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval2017\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m000000001296.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m cam(img_root)\n",
      "Cell \u001b[1;32mIn [12], line 6\u001b[0m, in \u001b[0;36mcal_cam.__init__\u001b[1;34m(self, feature_layer)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet50(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMatt\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.cache\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRN50.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 加载ResNet模型\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# clip_model, _ = clip.load(\"RN50\", device=\"cuda:0\")\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# clip_model = clip_model.to(torch.float)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# self.model = clip_model.visual\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1470\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;66;03m# copy state_dict so _load_from_state_dict can modify it\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(state_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1470\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;66;03m# mypy isn't aware that \"_metadata\" exists in state_dict\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m     state_dict\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m metadata  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\jit\\_script.py:764\u001b[0m, in \u001b[0;36mRecursiveScriptModule.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[attr] \u001b[38;5;241m=\u001b[39m script_method\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m script_method\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\jit\\_script.py:481\u001b[0m, in \u001b[0;36mScriptModule.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_actual_script_module\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m--> 481\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mScriptModule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_script_module, attr)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1185\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RecursiveScriptModule' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "cam = cal_cam()\n",
    "img_root = r\"H:\\Code\\AutoDL_backup\\datasets\\image_caption_generation\\COCO2017\\val2017\\000000001296.jpg\"\n",
    "cam(img_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
